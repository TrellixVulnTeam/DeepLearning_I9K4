{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing\n",
    "helper.download_dataset()\n",
    "train_val_dataset, test_dataset = helper.load_images_labels()\n",
    "train_images, train_labels = helper.extract_images_labels(train_val_dataset)\n",
    "test_images, test_labels = helper.extract_images_labels(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, inputs, hidden_layer1, hidden_layer2, outputs, batch_size=10000, learning_rate=0.1, epochs=1000):\n",
    "        \n",
    "        self.input_nodes = inputs\n",
    "        self.hidden_layer1_nodes = hidden_layer1\n",
    "        self.hidden_layer2_nodes = hidden_layer2\n",
    "        self.output_nodes = outputs\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        self.weights_input_to_hidden = np.random.normal(0.0, self.input_nodes**-0.5, (self.input_nodes, self.hidden_layer1_nodes))\n",
    "        self.weights_hidden_to_hidden = np.random.normal(0.0, self.hidden_layer1_nodes**-0.5, (self.hidden_layer1_nodes, self.hidden_layer2_nodes))\n",
    "        self.weights_hidden_to_output = np.random.normal(0.0, self.hidden_layer2_nodes**-0.5, (self.hidden_layer2_nodes, self.output_nodes))\n",
    "\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        \n",
    "        return 1/(1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_prime(self, x):\n",
    "        \n",
    "        return self.sigmoid(x) * (1 - self.sigmoid(x))\n",
    "    \n",
    "    def relu(self, x):\n",
    "        \n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def relu_prime(self, x):\n",
    "        \n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "        \n",
    "    def train_complete(self, images, targets):\n",
    "        \n",
    "        num_records = len(images)\n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            delta_weights_input_to_hidden = np.zeros(self.weights_input_to_hidden.shape)\n",
    "            delta_weights_hidden_to_hidden = np.zeros(self.weights_hidden_to_hidden.shape)\n",
    "            delta_weights_hidden_to_output = np.zeros(self.weights_hidden_to_output.shape)\n",
    "            \n",
    "            # forward pass\n",
    "            weights_hidden_layer1_in, weights_hidden_layer1_out, weights_hidden_layer2_in, \\\n",
    "                    weights_hidden_layer2_out, output_layer_in, final_outputs = self.forward_pass(images)\n",
    "            \n",
    "            # backpropagation\n",
    "            delta_weights_input_to_hidden, delta_weights_hidden_to_hidden, \\\n",
    "                        delta_weights_hidden_to_output = self.backpropagation(images, targets, weights_hidden_layer1_in, \\\n",
    "                        weights_hidden_layer1_out, weights_hidden_layer2_in, weights_hidden_layer2_out, output_layer_in, final_outputs, \\\n",
    "                        delta_weights_input_to_hidden, delta_weights_hidden_to_hidden, delta_weights_hidden_to_output)\n",
    "            \n",
    "            # Updating the weights\n",
    "            self.update_weights(delta_weights_input_to_hidden, delta_weights_hidden_to_hidden, delta_weights_hidden_to_output, num_records)\n",
    "            \n",
    "            # Calculating the error\n",
    "            train_error = self.calculate_MSE_error(final_outputs, targets)\n",
    "            validation_error, validation_accuracy = self.calculate_validation_stats()\n",
    "            \n",
    "            print(\"Epoch {0}, Training Error {1:0.3f}, Validation Error {2:0.3f}, Validation Accuracy {3:0.3f}\".format(i, train_error, validation_error, validation_accuracy))\n",
    "            \n",
    "                \n",
    "    def train_batches(self, images, targets):\n",
    "        \n",
    "        num_records = len(images)\n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            #computing the batches\n",
    "            for j in range(0, num_records, self.batch_size):\n",
    "                \n",
    "                batch_images = images[j: j + self.batch_size]\n",
    "                batch_targets = targets[j: j + self.batch_size]\n",
    "                \n",
    "                delta_weights_input_to_hidden = np.zeros(self.weights_input_to_hidden.shape)\n",
    "                delta_weights_hidden_to_hidden = np.zeros(self.weights_hidden_to_hidden.shape)\n",
    "                delta_weights_hidden_to_output = np.zeros(self.weights_hidden_to_output.shape)\n",
    "\n",
    "                # do the forward pass\n",
    "                weights_hidden_layer1_in, weights_hidden_layer1_out, weights_hidden_layer2_in, \\\n",
    "                        weights_hidden_layer2_out, output_layer_in, final_outputs = self.forward_pass(batch_images)\n",
    "                \n",
    "                # do the backpropagation\n",
    "                delta_weights_input_to_hidden, delta_weights_hidden_to_hidden, \\\n",
    "                        delta_weights_hidden_to_output = self.backpropagation(batch_images, batch_targets, weights_hidden_layer1_in, \\\n",
    "                        weights_hidden_layer1_out, weights_hidden_layer2_in,weights_hidden_layer2_out, output_layer_in, final_outputs, \\\n",
    "                        delta_weights_input_to_hidden, delta_weights_hidden_to_hidden, delta_weights_hidden_to_output)\n",
    "                \n",
    "                # Update the weights\n",
    "                self.update_weights(delta_weights_input_to_hidden, delta_weights_hidden_to_hidden, delta_weights_hidden_to_output, num_records)\n",
    "                \n",
    "                # Calculating the error\n",
    "                train_error = self.calculate_softmax_error(final_outputs, batch_targets)\n",
    "                validation_error, validation_accuracy = self.calculate_validation_stats()\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                print(\"Epoch {0}, Training Error {1:0.3f}, Validation Error {2:0.3f}, Validation Accuracy {3:0.3f}\".format(i, \\\n",
    "                                                                    train_error, validation_error, validation_accuracy))\n",
    "                \n",
    "                                      \n",
    "    def forward_pass(self, features):\n",
    "        \n",
    "        weights_hidden_layer1_in = np.dot(features, self.weights_input_to_hidden)\n",
    "        weights_hidden_layer1_out = self.sigmoid(weights_hidden_layer1_in)\n",
    "        \n",
    "        weights_hidden_layer2_in = np.dot(weights_hidden_layer1_out, self.weights_hidden_to_hidden)\n",
    "        weights_hidden_layer2_out = self.sigmoid(weights_hidden_layer2_in)\n",
    "        \n",
    "        output_layer_in = np.dot(weights_hidden_layer2_out, self.weights_hidden_to_output)\n",
    "        final_outputs = output_layer_in #self.sigmoid(output_layer_in)\n",
    "        \n",
    "        return weights_hidden_layer1_in, weights_hidden_layer1_out, weights_hidden_layer2_in, \\\n",
    "                weights_hidden_layer2_out, output_layer_in, final_outputs\n",
    "    \n",
    "    def backpropagation(self, features, labels, weights_hidden_layer1_in, weights_hidden_layer1_out, weights_hidden_layer2_in, \\\n",
    "                              weights_hidden_layer2_out, output_layer_in, final_outputs, \\\n",
    "                              delta_weights_input_to_hidden, delta_weights_hidden_to_hidden, delta_weights_hidden_to_output):\n",
    "\n",
    "        \"\"\" \n",
    "        Note: Error in output layer is the difference of predicted outputs to actual outputs\n",
    "              Error term would be the derivate of the activation function used in that layer. \n",
    "              Eg: x -> y -> z=f(y) here the activation function would be z. so error term would be error * f'(y)\n",
    "                  in case of sigmoid error * sig(y) * (1- sig(y)) ; here z = sig(y)\n",
    "                  so we can directly write error * z * (1-z) \n",
    "        \"\"\"\n",
    "        \n",
    "        error = labels - final_outputs\n",
    "        output_error_term = error #* self.sigmoid_prime(output_layer_in)\n",
    "        \n",
    "        hidden_layer2_error = np.dot(output_error_term, self.weights_hidden_to_output.T)\n",
    "        # we can also use the sigmoid prime method. here we are using direcly output of hidden layer\n",
    "        hidden_layer2_error_term = hidden_layer2_error * weights_hidden_layer2_out * (1 - weights_hidden_layer2_out) \n",
    "        \n",
    "        hidden_layer1_error = np.dot(hidden_layer2_error_term, self.weights_hidden_to_hidden.T)\n",
    "        # third way of writing the error term\n",
    "        hidden_layer1_error_term = hidden_layer1_error * self.sigmoid(weights_hidden_layer1_in) * (1 - self.sigmoid(weights_hidden_layer1_in))\n",
    "        \n",
    "        delta_weights_input_to_hidden += np.dot( features.T,  hidden_layer1_error_term )\n",
    "        delta_weights_hidden_to_hidden += np.dot(weights_hidden_layer1_out.T , hidden_layer2_error_term )\n",
    "        delta_weights_hidden_to_output += np.dot(weights_hidden_layer2_out.T , output_error_term)\n",
    "        \n",
    "        return delta_weights_input_to_hidden, delta_weights_hidden_to_hidden, delta_weights_hidden_to_output\n",
    "    \n",
    "    def update_weights(self, delta_weights_input_to_hidden, delta_weights_hidden_to_hidden, delta_weights_hidden_to_output, num_records):\n",
    "        \n",
    "        self.weights_input_to_hidden += self.learning_rate * delta_weights_input_to_hidden / num_records\n",
    "        self.weights_hidden_to_hidden += self.learning_rate * delta_weights_hidden_to_hidden / num_records\n",
    "        self.weights_hidden_to_output +=  self.learning_rate * delta_weights_hidden_to_output / num_records\n",
    "    \n",
    "    def calculate_MSE_error(self, final_outputs, labels):\n",
    "        error = (labels - final_outputs)**2\n",
    "        mean_error = np.sum(error)/labels.shape[0]\n",
    "        \n",
    "        return mean_error\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum()\n",
    "    \n",
    "    def calculate_softmax_error(self, final_ouputs, labels):\n",
    "        softmax = self.softmax(final_ouputs)\n",
    "        error = self.calculate_MSE_error(final_ouputs, labels)\n",
    "        return error\n",
    "                      \n",
    "    def calculate_validation_stats(self):\n",
    "        \n",
    "        validation_results = self.test(self.validation_features)\n",
    "        validation_error = self.calculate_softmax_error(validation_results, self.validation_targets)\n",
    "        \n",
    "        softmax_validation_results = self.softmax(validation_results)\n",
    "        round_validation_results = (softmax_validation_results == softmax_validation_results.max(axis=1)[:,None]).astype(int)\n",
    "        \n",
    "        labels_int = self.validation_targets.astype(int)\n",
    "        compare = np.sum((round_validation_results != labels_int).astype(int), axis=1)\n",
    "        correct = np.count_nonzero(compare == 0)\n",
    "        validation_accuracy = correct / self.validation_targets.shape[0]\n",
    "        \n",
    "        return validation_error, validation_accuracy\n",
    "        \n",
    "    def test(self, features):\n",
    "        \n",
    "        weights_hidden_layer1_in = np.dot(features, self.weights_input_to_hidden)\n",
    "        weights_hidden_layer1_out = self.sigmoid(weights_hidden_layer1_in)\n",
    "        \n",
    "        weights_hidden_layer2_in = np.dot(weights_hidden_layer1_out, self.weights_hidden_to_hidden)\n",
    "        weights_hidden_layer2_out = self.sigmoid(weights_hidden_layer2_in)\n",
    "        \n",
    "        output_layer_in = np.dot(weights_hidden_layer2_out, self.weights_hidden_to_output)\n",
    "        final_outputs = output_layer_in #self.sigmoid(output_layer_in)\n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "    def run(self, features, targets):\n",
    "        \n",
    "        import timeit\n",
    "\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_val, y_train, y_val = train_test_split( features, targets, test_size=0.2, random_state=42)\n",
    "        \n",
    "        self.validation_features = X_val\n",
    "        self.validation_targets = y_val\n",
    "\n",
    "#         start = timeit.timeit()\n",
    "#         self.train_complete(X_train, y_train)\n",
    "#         end = timeit.timeit()\n",
    "#         print(\"Time for training Neural Network using Complete batch: {0}\".format(end - start)) \n",
    "        \n",
    "        start = timeit.timeit()\n",
    "        self.train_batches(X_train, y_train)\n",
    "        end = timeit.timeit()\n",
    "        print(\"Time for training Neural Network using mini batches: {0}\".format(end - start)) \n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = NeuralNetwork(\n",
    "    inputs = 3072, \n",
    "    hidden_layer1 = 128, \n",
    "    hidden_layer2 = 32, \n",
    "    outputs = 10,\n",
    "    batch_size=10000, \n",
    "    learning_rate=0.25, \n",
    "    epochs=1000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network.run(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.794351077382\n"
     ]
    }
   ],
   "source": [
    "pred_outputs = network.test(test_images)\n",
    "error = network.calculate_softmax_error(pred_outputs, test_labels)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to Increase the accuracy :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
