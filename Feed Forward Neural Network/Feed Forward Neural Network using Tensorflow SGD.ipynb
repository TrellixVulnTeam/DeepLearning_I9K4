{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.download_dataset()\n",
    "train_val_dataset, test_dataset = helper.load_images_labels()\n",
    "train_val_images, train_val_labels = helper.extract_images_labels(train_val_dataset)\n",
    "test_images, test_labels = helper.extract_images_labels(test_dataset)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_val_images, train_val_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntax:\n",
    "\n",
    "1. placeholder: \n",
    "    - tf.placeholder(dtype, shape=None, name=None)\n",
    "2. Variable: \n",
    "    - tf.Variable(initial_values, name=None)\n",
    "    - tf.get_variable(name, shape=None, dtype=None)\n",
    "3. initialize values: \n",
    "    - tf.truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
    "    - tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
    "    - tf.zeros(shape, dtype=tf.float32, name=None)\n",
    "    - tf.ones(shape, dtype=tf.float32, name=None)  \n",
    "4. Mathematical Ops:\n",
    "    - tf.add()\n",
    "    - tf.matmul()\n",
    "    - tf.multiply()\n",
    "    - tf.log()\n",
    "5. Activation functions:\n",
    "    - tf.nn.relu(features, name=None)\n",
    "    - sigmoid\n",
    "    - tf.nn.softmax(logits, axis=None, name=None, dim=None)\n",
    "    - tf.nn.softmax_cross_entropy_with_logits_v2(_sentinel=None, labels=None, logits=None, dim=-1, name=None)\n",
    "6. Loss calculation:\n",
    "    - tf.reduce_sum(input_tensor,  axis=None, keepdims=None, name=None, reduction_indices=None)\n",
    "    - tf.reduce_mean(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None)\n",
    "7. Optimization functions:\n",
    "    - gradient descent\n",
    "    - Adam optimizer\n",
    "8. Session handling functions:\n",
    "    - tf.initialize_all_variables()\n",
    "    - tf.reset_default_graph()\n",
    "9. Saving model:\n",
    "    - tf.train.saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, num_inputs, num_outputs, num_hidden_layer1, num_hidden_layer2, learning_rate, epochs, batch_size):\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.inputs = tf.placeholder(tf.float32, shape=[None, num_inputs], name=\"inputs_placeholder\")\n",
    "        self.outputs = tf.placeholder(tf.float32, shape=[None, num_outputs], name=\"outputs_placeholder\")\n",
    "        \n",
    "        self.weights_input_to_hidden = self.getWeights([num_inputs, num_hidden_layer1], var_name=\"weights_input_to_hidden\")\n",
    "        self.weights_hidden_to_hidden = self.getWeights([num_hidden_layer1, num_hidden_layer2], var_name=\"weights_hidden_to_hidden\")\n",
    "        self.weights_hidden_to_output = self.getWeights([num_hidden_layer2, num_outputs], var_name=\"weights_hidden_to_ouput\")\n",
    "        \n",
    "        self.bias_hidden_layer1 = self.getBias([num_hidden_layer1], var_name=\"bias_hidden_layer1\")\n",
    "        self.bias_hidden_layer2 = self.getBias([num_hidden_layer2], var_name=\"bias_hidden_layer2\")\n",
    "        \n",
    "        saver = tf.train.Saver({\n",
    "            \"weights_input_to_hidden\" : self.weights_input_to_hidden,\n",
    "            \"weights_hidden_to_hidden\" : self.weights_hidden_to_hidden,\n",
    "            \"weights_hidden_to_ouput\" : self.weights_hidden_to_output,\n",
    "            \"bias_hidden_layer1\" : self.bias_hidden_layer1,\n",
    "            \"bias_hidden_layer2\" : self.bias_hidden_layer2,\n",
    "        })\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def getWeights(self, dim, var_name):\n",
    "        \n",
    "        return tf.Variable(tf.truncated_normal(shape=dim, mean=0.0, stddev=1.0, dtype=tf.float32), name=var_name)\n",
    "    \n",
    "    def getBias(self, dim, var_name):\n",
    "        \n",
    "        return tf.Variable(tf.ones(shape=dim, dtype=tf.float32), name=var_name)\n",
    "        \n",
    "    def train(self, train_features, train_targets, validation_features, validation_targets):\n",
    "        \n",
    "        #forward pass\n",
    "        hidden_layer1 = tf.add(tf.matmul(self.inputs, self.weights_input_to_hidden), self.bias_hidden_layer1)\n",
    "        hidden_layer1 = tf.nn.relu(hidden_layer1)\n",
    "        hidden_layer2 = tf.add(tf.matmul(hidden_layer1, self.weights_hidden_to_hidden), self.bias_hidden_layer2)\n",
    "        hidden_layer2 = tf.nn.relu(hidden_layer2)\n",
    "        logits = tf.matmul(hidden_layer2, self.weights_hidden_to_output)\n",
    "        \n",
    "        #loss function - softmax with cross entropy\n",
    "        softmax = tf.nn.softmax(logits)\n",
    "        softmax_log = tf.log(softmax)\n",
    "        cross_entropy = tf.matmul(self.outputs, softmax_log)\n",
    "        loss = -tf.reduce_sum(cross_entropy)\n",
    "        \n",
    "        #optimization function\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=self.learning_rate).minimize(loss)\n",
    "        \n",
    "        #accuracy\n",
    "        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(self.outputs, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "        #initializing the variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        save_file = \"./model.ckpt\"\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            \n",
    "            num_records = len(train_features)\n",
    "            for epoch in range(self.epochs):\n",
    "                for ii in range(0, num_records, self.batch_size):\n",
    "                    batch_features = train_features[ii: ii + self.batch_size]\n",
    "                    batch_targets = train_targets[ii: ii + self.batch_size]\n",
    "                    feed_dict = {\n",
    "                        self.inputs : batch_features,\n",
    "                        self.outputs : batch_targets\n",
    "                    }\n",
    "                    sess.run(optimizer, feed_dict=feed_dict)\n",
    "                    \n",
    "                if epoch % 2 == 0:\n",
    "                    validation_accuracy = sess.run(accuracy, feed_dict={\n",
    "                        self.inputs : validation_features,\n",
    "                        self.outputs : validation_targets\n",
    "                    })\n",
    "                    print(\"Epoch {:<3} Validation Accuracy {:0.3f}\".format(epoch, validation_accuracy))\n",
    "            \n",
    "            saver.save(sess, save_file)\n",
    "            print(\"Model is trained and saved to disk\")\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = NeuralNetwork(\n",
    "    num_inputs = 3072,\n",
    "    num_outputs = 10,\n",
    "    num_hidden_layer1 = 256,\n",
    "    num_hidden_layer2 = 64,\n",
    "    learning_rate = 0.1,\n",
    "    epochs = 100,\n",
    "    batch_size = 128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.train(train_images, train_labels, val_images, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
